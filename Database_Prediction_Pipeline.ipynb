{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jade-Isimbi/Prediction-Pipeline/blob/main/Database_Prediction_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StSDUdzLXqyt",
        "outputId": "1355b753-8bf6-4267-8362-0709c0cf632b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/331.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pymongo sqlalchemy kaggle pandas matplotlib plotly graphviz -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import json\n",
        "\n",
        "# Upload your kaggle.json file\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Upload your kaggle.json file\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Go to: https://www.kaggle.com/settings/account\")\n",
        "print(\"Scroll down to 'API' section and click 'Create New Token'\")\n",
        "print(\"This will download kaggle.json\")\n",
        "print(\"\\nNow upload it here:\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Setup Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: Downloading dataset from Kaggle...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "!kaggle datasets download -d patelris/crop-yield-prediction-dataset\n",
        "!unzip -o crop-yield-prediction-dataset.zip\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('yield_df.csv')\n",
        "\n",
        "print(\"\\n✓ Dataset loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "dImmL-WzYXaN",
        "outputId": "057a261f-cabc-4a7f-f6a0-a62f41b94039"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: Upload your kaggle.json file\n",
            "============================================================\n",
            "Go to: https://www.kaggle.com/settings/account\n",
            "Scroll down to 'API' section and click 'Create New Token'\n",
            "This will download kaggle.json\n",
            "\n",
            "Now upload it here:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a28918dc-ab92-49ef-a6a0-56f3c0d0691e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a28918dc-ab92-49ef-a6a0-56f3c0d0691e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "\n",
            "============================================================\n",
            "STEP 2: Downloading dataset from Kaggle...\n",
            "============================================================\n",
            "Dataset URL: https://www.kaggle.com/datasets/patelris/crop-yield-prediction-dataset\n",
            "License(s): world-bank\n",
            "Downloading crop-yield-prediction-dataset.zip to /content\n",
            "  0% 0.00/959k [00:00<?, ?B/s]\n",
            "100% 959k/959k [00:00<00:00, 586MB/s]\n",
            "Archive:  crop-yield-prediction-dataset.zip\n",
            "  inflating: pesticides.csv          \n",
            "  inflating: rainfall.csv            \n",
            "  inflating: temp.csv                \n",
            "  inflating: yield.csv               \n",
            "  inflating: yield_df.csv            \n",
            "\n",
            "✓ Dataset loaded successfully!\n",
            "Dataset shape: (28242, 8)\n",
            "\n",
            "Columns: ['Unnamed: 0', 'Area', 'Item', 'Year', 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']\n",
            "\n",
            "First few rows:\n",
            "   Unnamed: 0     Area         Item  Year  hg/ha_yield  \\\n",
            "0           0  Albania        Maize  1990        36613   \n",
            "1           1  Albania     Potatoes  1990        66667   \n",
            "2           2  Albania  Rice, paddy  1990        23333   \n",
            "3           3  Albania      Sorghum  1990        12500   \n",
            "4           4  Albania     Soybeans  1990         7000   \n",
            "\n",
            "   average_rain_fall_mm_per_year  pesticides_tonnes  avg_temp  \n",
            "0                         1485.0              121.0     16.37  \n",
            "1                         1485.0              121.0     16.37  \n",
            "2                         1485.0              121.0     16.37  \n",
            "3                         1485.0              121.0     16.37  \n",
            "4                         1485.0              121.0     16.37  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 3: DATA PREPROCESSING AND SCHEMA DESIGN\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3: Data Preprocessing\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Display basic statistics\n",
        "print(f\"\\nDataset Info:\")\n",
        "print(f\"Total records: {len(df)}\")\n",
        "print(f\"\\nColumns and types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nBasic statistics:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi1unmWCZYgc",
        "outputId": "b7f359b9-1bef-4fce-819f-ed0a3f5b43e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3: Data Preprocessing\n",
            "============================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total records: 28242\n",
            "\n",
            "Columns and types:\n",
            "unnamed:_0                         int64\n",
            "area                              object\n",
            "item                              object\n",
            "year                               int64\n",
            "hg/ha_yield                        int64\n",
            "average_rain_fall_mm_per_year    float64\n",
            "pesticides_tonnes                float64\n",
            "avg_temp                         float64\n",
            "dtype: object\n",
            "\n",
            "Basic statistics:\n",
            "         unnamed:_0          year    hg/ha_yield  \\\n",
            "count  28242.000000  28242.000000   28242.000000   \n",
            "mean   14120.500000   2001.544296   77053.332094   \n",
            "std     8152.907488      7.051905   84956.612897   \n",
            "min        0.000000   1990.000000      50.000000   \n",
            "25%     7060.250000   1995.000000   19919.250000   \n",
            "50%    14120.500000   2001.000000   38295.000000   \n",
            "75%    21180.750000   2008.000000  104676.750000   \n",
            "max    28241.000000   2013.000000  501412.000000   \n",
            "\n",
            "       average_rain_fall_mm_per_year  pesticides_tonnes      avg_temp  \n",
            "count                    28242.00000       28242.000000  28242.000000  \n",
            "mean                      1149.05598       37076.909344     20.542627  \n",
            "std                        709.81215       59958.784665      6.312051  \n",
            "min                         51.00000           0.040000      1.300000  \n",
            "25%                        593.00000        1702.000000     16.702500  \n",
            "50%                       1083.00000       17529.440000     21.510000  \n",
            "75%                       1668.00000       48687.880000     26.000000  \n",
            "max                       3240.00000      367778.000000     30.650000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 4: CREATE RELATIONAL DATABASE (SQLite)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4: Creating Relational Database (SQLite)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "# Create connection\n",
        "conn = sqlite3.connect('crop_yield.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Drop existing tables if they exist\n",
        "cursor.execute(\"DROP TABLE IF EXISTS yield_records\")\n",
        "cursor.execute(\"DROP TABLE IF EXISTS crops\")\n",
        "cursor.execute(\"DROP TABLE IF EXISTS countries\")\n",
        "cursor.execute(\"DROP TABLE IF EXISTS audit_log\")\n",
        "\n",
        "# Create Countries Table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE countries (\n",
        "    country_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    country_name VARCHAR(100) UNIQUE NOT NULL,\n",
        "    region VARCHAR(50),\n",
        "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "\"\"\")\n",
        "# Create Crops Table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE crops (\n",
        "    crop_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    crop_name VARCHAR(100) UNIQUE NOT NULL,\n",
        "    crop_category VARCHAR(50),\n",
        "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Create Yield Records Table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE yield_records (\n",
        "    record_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    country_id INTEGER NOT NULL,\n",
        "    crop_id INTEGER NOT NULL,\n",
        "    year INTEGER NOT NULL,\n",
        "    avg_temp REAL,\n",
        "    avg_rainfall_mm REAL,\n",
        "    pesticides_tonnes REAL,\n",
        "    yield_hg_per_ha REAL,\n",
        "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "    FOREIGN KEY (country_id) REFERENCES countries(country_id),\n",
        "    FOREIGN KEY (crop_id) REFERENCES crops(crop_id),\n",
        "    CHECK (year >= 1900 AND year <= 2100),\n",
        "    CHECK (yield_hg_per_ha >= 0)\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Create Audit Log Table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE audit_log (\n",
        "    log_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    table_name VARCHAR(50),\n",
        "    operation VARCHAR(20),\n",
        "    record_id INTEGER,\n",
        "    old_value TEXT,\n",
        "    new_value TEXT,\n",
        "    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "print(\"✓ Tables created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThuByepdZbQy",
        "outputId": "d701fa04-72f6-4cfc-e455-6376e8fe38e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4: Creating Relational Database (SQLite)\n",
            "============================================================\n",
            "✓ Tables created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 5: CREATE TRIGGER\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Creating Trigger\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Trigger to log updates to yield_records\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TRIGGER log_yield_updates\n",
        "AFTER UPDATE ON yield_records\n",
        "FOR EACH ROW\n",
        "BEGIN\n",
        "    INSERT INTO audit_log (table_name, operation, record_id, old_value, new_value)\n",
        "    VALUES (\n",
        "        'yield_records',\n",
        "        'UPDATE',\n",
        "        NEW.record_id,\n",
        "        json_object(\n",
        "            'yield', OLD.yield_hg_per_ha,\n",
        "            'rainfall', OLD.avg_rainfall_mm,\n",
        "            'temp', OLD.avg_temp\n",
        "        ),\n",
        "        json_object(\n",
        "            'yield', NEW.yield_hg_per_ha,\n",
        "            'rainfall', NEW.avg_rainfall_mm,\n",
        "            'temp', NEW.avg_temp\n",
        "        )\n",
        "    );\n",
        "END;\n",
        "\"\"\")\n",
        "\n",
        "# Trigger to automatically update updated_at timestamp\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TRIGGER update_timestamp\n",
        "AFTER UPDATE ON yield_records\n",
        "FOR EACH ROW\n",
        "BEGIN\n",
        "    UPDATE yield_records\n",
        "    SET updated_at = CURRENT_TIMESTAMP\n",
        "    WHERE record_id = NEW.record_id;\n",
        "END;\n",
        "\"\"\")\n",
        "\n",
        "print(\"✓ Triggers created successfully!\")\n",
        "print(\"  - log_yield_updates: Logs all updates to yield_records\")\n",
        "print(\"  - update_timestamp: Auto-updates timestamp on modifications\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjYKwZC2Zqwu",
        "outputId": "9c57ebfc-58f6-4cdc-841e-d87c0d8a3425"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 5: Creating Trigger\n",
            "============================================================\n",
            "✓ Triggers created successfully!\n",
            "  - log_yield_updates: Logs all updates to yield_records\n",
            "  - update_timestamp: Auto-updates timestamp on modifications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 6: CREATE STORED PROCEDURES (as Functions)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6: Creating Stored Procedures (Functions)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Note: SQLite doesn't support stored procedures natively,\n",
        "# so we'll create Python functions that perform the same operations\n",
        "\n",
        "def get_crop_statistics(crop_name):\n",
        "    \"\"\"\n",
        "    Stored Procedure: Get statistics for a specific crop\n",
        "    \"\"\"\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        c.crop_name,\n",
        "        COUNT(*) as total_records,\n",
        "        AVG(yr.yield_hg_per_ha) as avg_yield,\n",
        "        MIN(yr.yield_hg_per_ha) as min_yield,\n",
        "        MAX(yr.yield_hg_per_ha) as max_yield,\n",
        "        AVG(yr.avg_temp) as avg_temperature,\n",
        "        AVG(yr.avg_rainfall_mm) as avg_rainfall\n",
        "    FROM yield_records yr\n",
        "    JOIN crops c ON yr.crop_id = c.crop_id\n",
        "    WHERE c.crop_name = ?\n",
        "    GROUP BY c.crop_name\n",
        "    \"\"\"\n",
        "    cursor.execute(query, (crop_name,))\n",
        "    result = cursor.fetchone()\n",
        "\n",
        "    if result:\n",
        "        return {\n",
        "            'crop_name': result[0],\n",
        "            'total_records': result[1],\n",
        "            'avg_yield': round(result[2], 2),\n",
        "            'min_yield': round(result[3], 2),\n",
        "            'max_yield': round(result[4], 2),\n",
        "            'avg_temperature': round(result[5], 2),\n",
        "            'avg_rainfall': round(result[6], 2)\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def validate_and_insert_yield_record(country_name, crop_name, year,\n",
        "                                     avg_temp, avg_rainfall, pesticides, yield_val):\n",
        "    \"\"\"\n",
        "    Stored Procedure: Validate and insert a new yield record\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate inputs\n",
        "        if year < 1900 or year > 2100:\n",
        "            return False, \"Invalid year\"\n",
        "        if yield_val < 0:\n",
        "            return False, \"Yield cannot be negative\"\n",
        "\n",
        "        # Get or create country\n",
        "        cursor.execute(\"SELECT country_id FROM countries WHERE country_name = ?\", (country_name,))\n",
        "        country_row = cursor.fetchone()\n",
        "        if country_row:\n",
        "            country_id = country_row[0]\n",
        "        else:\n",
        "            cursor.execute(\"INSERT INTO countries (country_name) VALUES (?)\", (country_name,))\n",
        "            country_id = cursor.lastrowid\n",
        "\n",
        "        # Get or create crop\n",
        "        cursor.execute(\"SELECT crop_id FROM crops WHERE crop_name = ?\", (crop_name,))\n",
        "        crop_row = cursor.fetchone()\n",
        "        if crop_row:\n",
        "            crop_id = crop_row[0]\n",
        "        else:\n",
        "            cursor.execute(\"INSERT INTO crops (crop_name) VALUES (?)\", (crop_name,))\n",
        "            crop_id = cursor.lastrowid\n",
        "\n",
        "        # Insert yield record\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO yield_records\n",
        "            (country_id, crop_id, year, avg_temp, avg_rainfall_mm, pesticides_tonnes, yield_hg_per_ha)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (country_id, crop_id, year, avg_temp, avg_rainfall, pesticides, yield_val))\n",
        "\n",
        "        conn.commit()\n",
        "        return True, \"Record inserted successfully\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "print(\"✓ Stored Procedures (Functions) created successfully!\")\n",
        "print(\"  - get_crop_statistics(crop_name)\")\n",
        "print(\"  - validate_and_insert_yield_record(...)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQj5KOISZ-V1",
        "outputId": "8dc4d4d8-b292-453f-d60b-7d85eeb78159"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 6: Creating Stored Procedures (Functions)\n",
            "============================================================\n",
            "✓ Stored Procedures (Functions) created successfully!\n",
            "  - get_crop_statistics(crop_name)\n",
            "  - validate_and_insert_yield_record(...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 7: POPULATE DATABASE (FINAL CORRECTED VERSION)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7: Populating Database (Final Corrected Version)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Let's use the actual column names from the DataFrame\n",
        "df_working = df.copy()\n",
        "\n",
        "print(\"Actual columns in DataFrame:\")\n",
        "for i, col in enumerate(df_working.columns, 1):\n",
        "    print(f\"  {i}. '{col}'\")\n",
        "\n",
        "# Create a flexible column mapping based on actual column names\n",
        "column_mapping = {\n",
        "    'country_name': 'country_name',\n",
        "    'crop_name': 'crop_name',\n",
        "    'year': 'year',\n",
        "    'yield_hg_per_ha': 'yield_hg_per_ha',\n",
        "    'rainfall_mm': 'avg_rainfall_mm',  # This is the actual column name\n",
        "    'pesticides_tonnes': 'pesticides_tonnes',\n",
        "    'avg_temp': 'avg_temp'\n",
        "}\n",
        "\n",
        "# Verify all required columns exist\n",
        "required_columns = ['country_name', 'crop_name', 'year', 'yield_hg_per_ha', 'avg_rainfall_mm', 'pesticides_tonnes', 'avg_temp']\n",
        "missing_columns = [col for col in required_columns if col not in df_working.columns]\n",
        "\n",
        "if missing_columns:\n",
        "    print(f\"\\n⚠ Missing columns: {missing_columns}\")\n",
        "    print(\"Available columns:\")\n",
        "    for col in df_working.columns:\n",
        "        print(f\"  - '{col}'\")\n",
        "else:\n",
        "    print(f\"\\n✓ All required columns found!\")\n",
        "\n",
        "# Clear existing data to start fresh\n",
        "print(\"\\nClearing existing data...\")\n",
        "cursor.execute(\"DELETE FROM yield_records\")\n",
        "cursor.execute(\"DELETE FROM countries\")\n",
        "cursor.execute(\"DELETE FROM crops\")\n",
        "cursor.execute(\"DELETE FROM audit_log\")\n",
        "conn.commit()\n",
        "print(\"✓ Cleared existing data\")\n",
        "\n",
        "# Insert unique countries\n",
        "print(\"\\n1. Inserting countries...\")\n",
        "unique_countries = df_working['area'].unique() # Changed from country_name to area\n",
        "print(f\"Found {len(unique_countries)} unique countries\")\n",
        "\n",
        "countries_inserted = 0\n",
        "for country in unique_countries:\n",
        "    try:\n",
        "        cursor.execute(\"INSERT INTO countries (country_name) VALUES (?)\", (country,))\n",
        "        countries_inserted += 1\n",
        "    except Exception as e:\n",
        "        # Ignore duplicate errors due to UNIQUE constraint\n",
        "        if \"UNIQUE constraint\" not in str(e):\n",
        "            print(f\"Error inserting country '{country}': {e}\")\n",
        "\n",
        "conn.commit()\n",
        "print(f\"✓ Inserted {countries_inserted} countries\")\n",
        "\n",
        "# Insert unique crops\n",
        "print(\"\\n2. Inserting crops...\")\n",
        "unique_crops = df_working['item'].unique() # Changed from crop_name to item\n",
        "print(f\"Found {len(unique_crops)} unique crops\")\n",
        "\n",
        "crops_inserted = 0\n",
        "for crop in unique_crops:\n",
        "    try:\n",
        "        cursor.execute(\"INSERT INTO crops (crop_name) VALUES (?)\", (crop,))\n",
        "        crops_inserted += 1\n",
        "    except Exception as e:\n",
        "        # Ignore duplicate errors due to UNIQUE constraint\n",
        "        if \"UNIQUE constraint\" not in str(e):\n",
        "            print(f\"Error inserting crop '{crop}': {e}\")\n",
        "\n",
        "conn.commit()\n",
        "print(f\"✓ Inserted {crops_inserted} crops\")\n",
        "\n",
        "# Verify country and crop IDs were created\n",
        "cursor.execute(\"SELECT COUNT(*) FROM countries\")\n",
        "country_count = cursor.fetchone()[0]\n",
        "cursor.execute(\"SELECT COUNT(*) FROM crops\")\n",
        "crop_count = cursor.fetchone()[0]\n",
        "print(f\"\\nDatabase now has {country_count} countries and {crop_count} crops\")\n",
        "\n",
        "# Insert yield records - USING ACTUAL COLUMN NAMES\n",
        "print(\"\\n3. Inserting yield records...\")\n",
        "records_inserted = 0\n",
        "errors = 0\n",
        "\n",
        "# Create a mapping dictionary for country and crop names to IDs\n",
        "cursor.execute(\"SELECT country_id, country_name FROM countries\")\n",
        "country_map = {name: cid for cid, name in cursor.fetchall()}\n",
        "\n",
        "cursor.execute(\"SELECT crop_id, crop_name FROM crops\")\n",
        "crop_map = {name: cid for cid, name in cursor.fetchall()}\n",
        "\n",
        "# Insert records in batches for better performance\n",
        "batch_size = 1000\n",
        "batch_records = []\n",
        "\n",
        "for idx, row in df_working.iterrows():\n",
        "    try:\n",
        "        # Use ACTUAL column names from the DataFrame\n",
        "        country_name = row['area'] # Changed from country_name to area\n",
        "        crop_name = row['item'] # Changed from crop_name to item\n",
        "        year = int(row['year'])\n",
        "        yield_value = float(row['hg/ha_yield'])\n",
        "        rainfall_mm = float(row['average_rain_fall_mm_per_year'])  # This is the correct column name\n",
        "        pesticides_tonnes = float(row['pesticides_tonnes'])\n",
        "        avg_temp = float(row['avg_temp'])\n",
        "\n",
        "        # Get IDs from our mapping\n",
        "        country_id = country_map.get(country_name)\n",
        "        crop_id = crop_map.get(crop_name)\n",
        "\n",
        "        if not country_id:\n",
        "            print(f\"Warning: Country '{country_name}' not found in mapping\")\n",
        "            errors += 1\n",
        "            continue\n",
        "\n",
        "        if not crop_id:\n",
        "            print(f\"Warning: Crop '{crop_name}' not found in mapping\")\n",
        "            errors += 1\n",
        "            continue\n",
        "\n",
        "        # Add to batch\n",
        "        batch_records.append((\n",
        "            country_id, crop_id, year, avg_temp, rainfall_mm,\n",
        "            pesticides_tonnes, yield_value\n",
        "        ))\n",
        "\n",
        "        # Insert batch when it reaches batch_size\n",
        "        if len(batch_records) >= batch_size:\n",
        "            cursor.executemany(\"\"\"\n",
        "                INSERT INTO yield_records\n",
        "                (country_id, crop_id, year, avg_temp, avg_rainfall_mm, pesticides_tonnes, yield_hg_per_ha)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\", batch_records)\n",
        "            records_inserted += len(batch_records)\n",
        "            batch_records = []\n",
        "            print(f\"  Inserted {records_inserted} records...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        errors += 1\n",
        "        if errors <= 3:  # Only show first few errors\n",
        "            print(f\"Error at row {idx}: {e}\")\n",
        "            print(f\"  Row data: {dict(row)}\")\n",
        "        continue\n",
        "\n",
        "# Insert any remaining records in the final batch\n",
        "if batch_records:\n",
        "    cursor.executemany(\"\"\"\n",
        "        INSERT INTO yield_records\n",
        "        (country_id, crop_id, year, avg_temp, avg_rainfall_mm, pesticides_tonnes, yield_hg_per_ha)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", batch_records)\n",
        "    records_inserted += len(batch_records)\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "print(f\"\\n✓ Insertion completed!\")\n",
        "print(f\"  Successfully inserted: {records_inserted} records\")\n",
        "print(f\"  Errors encountered: {errors} records\")\n",
        "print(f\"  Total processed: {records_inserted + errors} records\")\n",
        "\n",
        "# Verify the insertion\n",
        "cursor.execute(\"SELECT COUNT(*) FROM yield_records\")\n",
        "final_count = cursor.fetchone()[0]\n",
        "print(f\"✓ Database now contains {final_count} yield records\")\n",
        "\n",
        "# Show sample of inserted data\n",
        "if final_count > 0:\n",
        "    print(\"\\nSample of inserted data:\")\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT c.country_name, cr.crop_name, yr.year, yr.yield_hg_per_ha\n",
        "        FROM yield_records yr\n",
        "        JOIN countries c ON yr.country_id = c.country_id\n",
        "        JOIN crops cr ON yr.crop_id = cr.crop_id\n",
        "        LIMIT 5\n",
        "    \"\"\")\n",
        "    sample_data = cursor.fetchall()\n",
        "    for row in sample_data:\n",
        "        print(f\"  {row[0]} - {row[1]} ({row[2]}): {row[3]:,.0f} hg/ha\")\n",
        "\n",
        "    # Show some statistics\n",
        "    print(f\"\\nDatabase Statistics:\")\n",
        "    cursor.execute(\"SELECT MIN(year), MAX(year) FROM yield_records\")\n",
        "    min_year, max_year = cursor.fetchone()\n",
        "    print(f\"  Year range: {min_year} - {max_year}\")\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(DISTINCT country_id) FROM yield_records\")\n",
        "    unique_countries = cursor.fetchone()[0]\n",
        "    print(f\"  Countries with data: {unique_countries}\")\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(DISTINCT crop_id) FROM yield_records\")\n",
        "    unique_crops = cursor.fetchone()[0]\n",
        "    print(f\"  Crops with data: {unique_crops}\")\n",
        "else:\n",
        "    print(\"\\n⚠ No records were inserted. Debugging info:\")\n",
        "    print(f\"  Total rows in DataFrame: {len(df_working)}\")\n",
        "    print(f\"  First row sample: {dict(df_working.iloc[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfx1PANkaID_",
        "outputId": "459666a7-a130-4565-d424-29457f25d978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 7: Populating Database (Final Corrected Version)\n",
            "============================================================\n",
            "Actual columns in DataFrame:\n",
            "  1. 'unnamed:_0'\n",
            "  2. 'area'\n",
            "  3. 'item'\n",
            "  4. 'year'\n",
            "  5. 'hg/ha_yield'\n",
            "  6. 'average_rain_fall_mm_per_year'\n",
            "  7. 'pesticides_tonnes'\n",
            "  8. 'avg_temp'\n",
            "\n",
            "⚠ Missing columns: ['country_name', 'crop_name', 'yield_hg_per_ha', 'avg_rainfall_mm']\n",
            "Available columns:\n",
            "  - 'unnamed:_0'\n",
            "  - 'area'\n",
            "  - 'item'\n",
            "  - 'year'\n",
            "  - 'hg/ha_yield'\n",
            "  - 'average_rain_fall_mm_per_year'\n",
            "  - 'pesticides_tonnes'\n",
            "  - 'avg_temp'\n",
            "\n",
            "Clearing existing data...\n",
            "✓ Cleared existing data\n",
            "\n",
            "1. Inserting countries...\n",
            "Found 101 unique countries\n",
            "✓ Inserted 101 countries\n",
            "\n",
            "2. Inserting crops...\n",
            "Found 10 unique crops\n",
            "✓ Inserted 10 crops\n",
            "\n",
            "Database now has 101 countries and 10 crops\n",
            "\n",
            "3. Inserting yield records...\n",
            "  Inserted 1000 records...\n",
            "  Inserted 2000 records...\n",
            "  Inserted 3000 records...\n",
            "  Inserted 4000 records...\n",
            "  Inserted 5000 records...\n",
            "  Inserted 6000 records...\n",
            "  Inserted 7000 records...\n",
            "  Inserted 8000 records...\n",
            "  Inserted 9000 records...\n",
            "  Inserted 10000 records...\n",
            "  Inserted 11000 records...\n",
            "  Inserted 12000 records...\n",
            "  Inserted 13000 records...\n",
            "  Inserted 14000 records...\n",
            "  Inserted 15000 records...\n",
            "  Inserted 16000 records...\n",
            "  Inserted 17000 records...\n",
            "  Inserted 18000 records...\n",
            "  Inserted 19000 records...\n",
            "  Inserted 20000 records...\n",
            "  Inserted 21000 records...\n",
            "  Inserted 22000 records...\n",
            "  Inserted 23000 records...\n",
            "  Inserted 24000 records...\n",
            "  Inserted 25000 records...\n",
            "  Inserted 26000 records...\n",
            "  Inserted 27000 records...\n",
            "  Inserted 28000 records...\n",
            "\n",
            "✓ Insertion completed!\n",
            "  Successfully inserted: 28242 records\n",
            "  Errors encountered: 0 records\n",
            "  Total processed: 28242 records\n",
            "✓ Database now contains 28242 yield records\n",
            "\n",
            "Sample of inserted data:\n",
            "  Albania - Maize (1990): 36,613 hg/ha\n",
            "  Albania - Potatoes (1990): 66,667 hg/ha\n",
            "  Albania - Rice, paddy (1990): 23,333 hg/ha\n",
            "  Albania - Sorghum (1990): 12,500 hg/ha\n",
            "  Albania - Soybeans (1990): 7,000 hg/ha\n",
            "\n",
            "Database Statistics:\n",
            "  Year range: 1990 - 2013\n",
            "  Countries with data: 101\n",
            "  Crops with data: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 8: TEST STORED PROCEDURES AND TRIGGERS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 8: Testing Stored Procedures and Triggers\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test stored procedure - get_crop_statistics\n",
        "print(\"\\n1. Testing get_crop_statistics()...\")\n",
        "cursor.execute(\"SELECT crop_name FROM crops LIMIT 3\")\n",
        "sample_crops = cursor.fetchall()\n",
        "\n",
        "for crop_row in sample_crops:\n",
        "    crop_name = crop_row[0]\n",
        "    stats = get_crop_statistics(crop_name)\n",
        "    if stats:\n",
        "        print(f\"\\n Statistics for {crop_name}:\")\n",
        "        print(f\"   Total Records: {stats['total_records']}\")\n",
        "        print(f\"   Average Yield: {stats['avg_yield']:,.2f} hg/ha\")\n",
        "        print(f\"   Min Yield: {stats['min_yield']:,.2f} hg/ha\")\n",
        "        print(f\"   Max Yield: {stats['max_yield']:,.2f} hg/ha\")\n",
        "        print(f\"   Avg Temperature: {stats['avg_temperature']:.2f}°C\")\n",
        "        print(f\"   Avg Rainfall: {stats['avg_rainfall']:.2f} mm\")\n",
        "\n",
        "# Test the insert stored procedure\n",
        "print(\"\\n2. Testing validate_and_insert_yield_record()...\")\n",
        "test_cases = [\n",
        "    # Valid case\n",
        "    (\"Test Country\", \"Test Crop\", 2020, 20.5, 1000.0, 500.0, 50000.0),\n",
        "    # Invalid year\n",
        "    (\"Test Country\", \"Test Crop\", 1800, 20.5, 1000.0, 500.0, 50000.0),\n",
        "    # Negative yield\n",
        "    (\"Test Country\", \"Test Crop\", 2020, 20.5, 1000.0, 500.0, -100.0)\n",
        "]\n",
        "\n",
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    success, message = validate_and_insert_yield_record(*test_case)\n",
        "    status = \"✓ SUCCESS\" if success else \"✗ FAILED\"\n",
        "    print(f\"   Test {i}: {status} - {message}\")\n",
        "\n",
        "# Test trigger by updating a record\n",
        "print(\"\\n3. Testing trigger (updating a record)...\")\n",
        "cursor.execute(\"\"\"\n",
        "    SELECT record_id, yield_hg_per_ha, avg_temp, avg_rainfall_mm\n",
        "    FROM yield_records\n",
        "    LIMIT 1\n",
        "\"\"\")\n",
        "test_record = cursor.fetchone()\n",
        "\n",
        "if test_record:\n",
        "    record_id, old_yield, old_temp, old_rainfall = test_record\n",
        "    new_yield = old_yield * 1.15  # Increase by 15%\n",
        "    new_temp = old_temp + 1.0     # Increase temperature by 1°C\n",
        "\n",
        "    print(f\"   Updating record {record_id}:\")\n",
        "    print(f\"     Yield: {old_yield:,.0f} → {new_yield:,.0f} hg/ha\")\n",
        "    print(f\"     Temperature: {old_temp:.1f} → {new_temp:.1f}°C\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        UPDATE yield_records\n",
        "        SET yield_hg_per_ha = ?, avg_temp = ?\n",
        "        WHERE record_id = ?\n",
        "    \"\"\", (new_yield, new_temp, record_id))\n",
        "    conn.commit()\n",
        "\n",
        "    # Check audit log\n",
        "    cursor.execute(\"SELECT * FROM audit_log ORDER BY log_id DESC LIMIT 1\")\n",
        "    audit_entry = cursor.fetchone()\n",
        "\n",
        "    if audit_entry:\n",
        "        print(f\"\\n   ✓ Audit Log Entry Created:\")\n",
        "        print(f\"     Log ID: {audit_entry[0]}\")\n",
        "        print(f\"     Table: {audit_entry[1]}\")\n",
        "        print(f\"     Operation: {audit_entry[2]}\")\n",
        "        print(f\"     Record ID: {audit_entry[3]}\")\n",
        "        print(f\"     Changed At: {audit_entry[6]}\")\n",
        "\n",
        "        # Parse JSON data\n",
        "        import json\n",
        "        try:\n",
        "            old_data = json.loads(audit_entry[4]) if audit_entry[4] else {}\n",
        "            new_data = json.loads(audit_entry[5]) if audit_entry[5] else {}\n",
        "            print(f\"     Old Values: Yield={old_data.get('yield', 'N/A')}, Temp={old_data.get('temp', 'N/A')}\")\n",
        "            print(f\"     New Values: Yield={new_data.get('yield', 'N/A')}, Temp={new_data.get('temp', 'N/A')}\")\n",
        "        except Exception as e:\n",
        "            print(f\"     JSON Parse Error: {e}\")\n",
        "    else:\n",
        "        print(\"   ⚠ No audit log entry found\")\n",
        "else:\n",
        "    print(\"   ⚠ No records found to test trigger\")\n",
        "\n",
        "# Test updated_at trigger\n",
        "print(\"\\n4. Testing updated_at timestamp trigger...\")\n",
        "cursor.execute(\"SELECT record_id, updated_at FROM yield_records LIMIT 1\")\n",
        "record_before = cursor.fetchone()\n",
        "\n",
        "if record_before:\n",
        "    record_id, old_updated_at = record_before\n",
        "    cursor.execute(\"\"\"\n",
        "        UPDATE yield_records\n",
        "        SET yield_hg_per_ha = yield_hg_per_ha + 1000\n",
        "        WHERE record_id = ?\n",
        "    \"\"\", (record_id,))\n",
        "    conn.commit()\n",
        "\n",
        "    cursor.execute(\"SELECT updated_at FROM yield_records WHERE record_id = ?\", (record_id,))\n",
        "    new_updated_at = cursor.fetchone()[0]\n",
        "\n",
        "    print(f\"   Record {record_id}:\")\n",
        "    print(f\"     Before update: {old_updated_at}\")\n",
        "    print(f\"     After update:  {new_updated_at}\")\n",
        "    print(f\"     ✓ Timestamp updated: {old_updated_at != new_updated_at}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz_pqOpt2Qdv",
        "outputId": "1e96588e-68a1-4c07-c4af-22ef47ee1f9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 8: Testing Stored Procedures and Triggers\n",
            "============================================================\n",
            "\n",
            "1. Testing get_crop_statistics()...\n",
            "\n",
            "2. Testing validate_and_insert_yield_record()...\n",
            "   Test 1: ✓ SUCCESS - Record inserted successfully\n",
            "   Test 2: ✗ FAILED - Invalid year\n",
            "   Test 3: ✗ FAILED - Yield cannot be negative\n",
            "\n",
            "3. Testing trigger (updating a record)...\n",
            "   Updating record 1:\n",
            "     Yield: 50,000 → 57,500 hg/ha\n",
            "     Temperature: 20.5 → 21.5°C\n",
            "\n",
            "   ✓ Audit Log Entry Created:\n",
            "     Log ID: 2\n",
            "     Table: yield_records\n",
            "     Operation: UPDATE\n",
            "     Record ID: 1\n",
            "     Changed At: 2025-11-02 18:34:05\n",
            "     Old Values: Yield=50000.0, Temp=20.5\n",
            "     New Values: Yield=57500.0, Temp=21.5\n",
            "\n",
            "4. Testing updated_at timestamp trigger...\n",
            "   Record 1:\n",
            "     Before update: 2025-11-02 18:34:05\n",
            "     After update:  2025-11-02 18:34:05\n",
            "     ✓ Timestamp updated: False\n"
          ]
        }
      ]
    }
  ]
}